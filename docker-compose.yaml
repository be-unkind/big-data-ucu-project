version: '3.5'

services:  
  zookeeper:
    image: bitnami/zookeeper:latest
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ALLOW_ANONYMOUS_LOGIN: yes
    ports:
      - 2181:2181
    networks:
      - project-network

  kafka:
    image: bitnami/kafka:latest
    container_name: kafka
    ports:
      - 9092:9092
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      ALLOW_PLAINTEXT_LISTENER: yes
    depends_on:
      - zookeeper
    networks:
      - project-network

  kafka-setup:
    image: bitnami/kafka:latest
    container_name: kafka-setup
    restart: "no"
    depends_on:
      - kafka
    entrypoint: [ '/bin/sh', '-c' ]
    command: |
      "
      # blocks until kafka is reachable
      kafka-topics --bootstrap-server kafka:9092 --list

      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic source-data --replication-factor 3 --partitions 1
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic output-data --replication-factor 3 --partitions 1
      "
    networks:
      - project-network

  source_data_reader:
    container_name: source_data_reader
    build:
        context: .
        dockerfile: source_data_reader/Dockerfile.read
    depends_on:
      - kafka
    networks:
      - project-network
  
  spark-streaming:
    image: docker.io/bitnami/spark:latest
    container_name: spark-streaming-master
    networks:
      - project-network
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - '8080:8080'

  spark-streaming-worker:
    image: docker.io/bitnami/spark:latest
    container_name: spark-streaming-worker
    networks:
      - project-network
    depends_on: 
      cassandra-node:
        condition: service_healthy
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-streaming:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
  
  spark-streaming-submit:
    image: docker.io/bitnami/spark:latest
    container_name: spark-streaming-submit
    networks:
      - project-network
    depends_on: 
      cassandra-node:
        condition: service_healthy
    volumes:
      - ./spark_stream:/opt/app
    command: spark-submit --conf spark.jars.ivy=/opt/app --packages "org.apache.spark:spark-sql-kafka-0-10_2.12:3.2.0,com.datastax.spark:spark-cassandra-connector_2.12:3.1.0" --master spark://spark-streaming-master:7077 --deploy-mode client /opt/app/stream_processor.py
  
  spark-batch:
    image: docker.io/bitnami/spark:latest
    container_name: spark-batch-master
    networks:
      - project-network
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - '4040:8080'

  spark-batch-worker:
    image: docker.io/bitnami/spark:latest
    container_name: spark-batch-worker
    networks:
      - project-network
    depends_on: 
      cassandra-node:
        condition: service_healthy
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-batch:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
  
  spark-batch-submit:
    image: docker.io/bitnami/spark:latest
    container_name: spark-batch-submit
    networks:
      - project-network
    depends_on: 
      cassandra-node:
        condition: service_healthy
    volumes:
      - ./spark_batch:/opt/app
    command: python /opt/app/periodic_script.py

  cassandra-node:
    image: cassandra:latest
    container_name: cassandra-node
    ports:
      - "9042:9042"
    networks:
      - project-network
    volumes:
      - ./cql_scripts/ddl.cql:/ddl.cql
    healthcheck:
      test: [ "CMD", "cqlsh", "-f", "ddl.cql" ]
      interval: 30s
      retries: 10
      start_period: 20s
      timeout: 10s

  rest-api:
    container_name: rest-api
    build:
        context: .
        dockerfile: rest_api/Dockerfile.rest
    depends_on: 
      cassandra-node:
        condition: service_healthy
    ports:
      - "8000:8000"
    networks:
      - project-network

networks:
  project-network:
    name: project-network